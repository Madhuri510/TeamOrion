{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccc8b80-d384-4c6d-b20b-8c4e349c9b94",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070e6bb1-c414-449c-9e2e-d70ef0e9d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f381c07-00e8-429c-9db6-72e9eb22457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18611318-7d85-488a-bb57-bac2e06cc6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in ./miniforge3/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in ./miniforge3/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in ./miniforge3/lib/python3.10/site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in ./miniforge3/lib/python3.10/site-packages (from openai==0.28) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniforge3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniforge3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniforge3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniforge3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./miniforge3/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2547de1-d190-46e3-b0be-7bc92b482099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in ./miniforge3/lib/python3.10/site-packages (0.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d6cb28-6489-4211-9336-4eb8b072a553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vedant/miniforge3/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328d1f68-75ca-421e-b7be-764714b11468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in ./miniforge3/lib/python3.10/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c729911-3a23-4bec-8ef0-b2e015a4a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6791b30a-9d89-4461-b579-e023bfd90b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c34d0fe-9f3b-4e79-961e-39ee8157c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./miniforge3/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: transformers in ./miniforge3/lib/python3.10/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in ./miniforge3/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./miniforge3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./miniforge3/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./miniforge3/lib/python3.10/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in ./miniforge3/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./miniforge3/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./miniforge3/lib/python3.10/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniforge3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniforge3/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniforge3/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniforge3/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in ./miniforge3/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./miniforge3/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./miniforge3/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniforge3/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniforge3/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniforge3/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniforge3/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniforge3/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniforge3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826d9ae-8f81-4fe1-a2eb-ae9ee7768f9a",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337689c2-3acc-484e-a92f-93c0c91e5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85837254-9a7c-4d6c-91be-6fb66403a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pubmed_count(query):\n",
    "    \"\"\"Fetch the total count of articles for the query.\"\"\"\n",
    "    search_url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retmode=json&retmax=1\"\n",
    "    try:\n",
    "        response = requests.get(search_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return int(data['esearchresult']['count'])\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to retrieve PubMed count: {e}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24165a-0a61-4caf-8820-30c91df6627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubmed_for_ids(query, retstart=0, retmax=10000):\n",
    "    \"\"\"Search PubMed for articles and return a list of PubMed IDs based on pagination.\"\"\"\n",
    "    search_url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retmode=json&retmax={retmax}&retstart={retstart}\"\n",
    "    try:\n",
    "        response = requests.get(search_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data['esearchresult']['idlist']\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to retrieve PubMed IDs: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1ddab-dc7a-495c-92f5-d42e5c9f969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_abstract(pubmed_id, session, params):\n",
    "    \"\"\"Fetch an abstract from PubMed based on the PubMed ID.\"\"\"\n",
    "    params['id'] = pubmed_id\n",
    "    try:\n",
    "        response = session.get(\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\", params=params)\n",
    "        response.raise_for_status()\n",
    "        root = ET.fromstring(response.text)\n",
    "\n",
    "        # Extract abstract texts\n",
    "        abstract_text_elements = root.findall('.//AbstractText')\n",
    "        abstract_text = ' '.join(''.join(element.itertext()).strip() for element in abstract_text_elements if element.text)\n",
    "        \n",
    "        # Extract MeSH headings\n",
    "        mesh_heading_elements = root.findall('.//MeshHeading/DescriptorName')\n",
    "        mesh_headings = ', '.join([element.text for element in mesh_heading_elements if element.text])\n",
    "\n",
    "        return abstract_text, mesh_headings\n",
    "\n",
    "    except (requests.RequestException, ET.ParseError) as e:\n",
    "        logging.error(f\"Error fetching data for PubMed ID {pubmed_id}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccdfa7-eb0a-4223-9799-11dea93a79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi'\n",
    "\n",
    "def clean_response_text(response_text):\n",
    "    \"\"\"Remove invalid control characters and return cleaned text.\"\"\"\n",
    "    cleaned_text = ''.join(c for c in response_text if c.isprintable())\n",
    "    return cleaned_text\n",
    "\n",
    "def write_abstracts_to_csv(abstract_ids, api_key):\n",
    "    \"\"\"Fetch abstracts for a list of PubMed IDs and write them to a CSV file.\"\"\"\n",
    "    file_exists = os.path.isfile('pubmed_abstracts_with_mesh.csv')\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'rettype': 'abstract',\n",
    "        'api_key': api_key,\n",
    "    }\n",
    "    batch_size = 200 \n",
    "    total_abstract_count = 0\n",
    "    valid_abstract_count = 0\n",
    "    null_abstract_count = 0\n",
    "\n",
    "    with open('pubmed_abstracts_with_mesh.csv', mode='a' if file_exists else 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row only if the file is being created (i.e., it does not already exist)\n",
    "        if not file_exists:\n",
    "            writer.writerow(['PubMedID', 'Abstract', 'Mesh Headings'])\n",
    "        \n",
    "        for i in range(0, len(abstract_ids), batch_size):\n",
    "            batch_ids = abstract_ids[i:i + batch_size]\n",
    "            params['id'] = ','.join(batch_ids)\n",
    "\n",
    "            # Add a sleep to avoid hitting rate limits\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            response = requests.get(base_url, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                total_abstract_count += len(batch_ids)\n",
    "\n",
    "                # Clean and parse the XML content\n",
    "                cleaned_response = clean_response_text(response.text)\n",
    "\n",
    "                try:\n",
    "                    root = ET.fromstring(cleaned_response)\n",
    "\n",
    "                    # Find all elements with the tag 'AbstractText'\n",
    "                    abstract_text_elements = root.findall('.//AbstractText')\n",
    "                    abstract_texts = ' '.join(' '.join(element.itertext()).strip() for element in abstract_text_elements if element.text)\n",
    "\n",
    "                    # Find all the MeshHeadings\n",
    "                    mesh_heading_elements = root.findall('.//MeshHeading/DescriptorName')\n",
    "                    mesh_headings = ', '.join([element.text for element in mesh_heading_elements if element.text])\n",
    "\n",
    "                    # Write the PubMed ID and combined abstract into the CSV\n",
    "                    for pubmed_id in batch_ids:\n",
    "                        if abstract_texts:  # Only write if abstract is not null\n",
    "                            writer.writerow([pubmed_id, abstract_texts, mesh_headings])\n",
    "                            valid_abstract_count += 1\n",
    "                        else:\n",
    "                            null_abstract_count += 1\n",
    "\n",
    "                except ET.ParseError as e:\n",
    "                    logging.error(f\"XML parsing error for batch starting with PubMed ID {batch_ids[0]}: {e}\")\n",
    "                    logging.error(f\"Response content: {cleaned_response[:500]}\")  # Log first 500 chars of the response\n",
    "\n",
    "            else:\n",
    "                logging.error(f\"Failed to fetch data for batch starting with PubMed ID {batch_ids[0]}. Status code: {response.status_code}\")\n",
    "\n",
    "    # Log the results\n",
    "    logging.info(f'Total Accessed Abstracts: {total_abstract_count}')\n",
    "    logging.info(f'Valid Abstracts: {valid_abstract_count}')\n",
    "    logging.info(f'Null Abstracts: {null_abstract_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac39db-5f11-4fc5-9e7a-614164e98c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_pubmed_abstracts(keywords, api_key):\n",
    "    \"\"\"Download all abstracts based on keywords, utilizing pagination.\"\"\"\n",
    "    query = '+'.join(keywords)\n",
    "    total_count = fetch_pubmed_count(query)\n",
    "    batch_size = 10000\n",
    "\n",
    "    # Iterate through all records using pagination\n",
    "    for start in range(0, total_count, batch_size):\n",
    "        logging.info(f\"Fetching records {start} to {start + batch_size}\")\n",
    "        abstract_ids = search_pubmed_for_ids(query, retstart=start, retmax=batch_size)\n",
    "        write_abstracts_to_csv(abstract_ids, api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f6464-79cc-450c-b52a-0bd06be20288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keywords = [\"Neoplasms\", \"Antineoplastic Agents\", \"Adverse Effects\", \"Toxicity\"]\n",
    "api_key = 'd4a0e5f85881f5f38b9c0e9a84ac5338e408'  \n",
    "download_all_pubmed_abstracts(keywords, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e885cde-c69e-4d48-b76b-9552699e4aa9",
   "metadata": {},
   "source": [
    "## Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f70fb0-4edd-4a8c-b73d-bf99b4163122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove special characters (keeping letters, numbers, and whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Remove formulas (anything in parentheses)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove any HTTP requests\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    \n",
    "    # Trim whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('pubmed_abstracts_with_mesh1.csv')\n",
    "\n",
    "# Apply preprocessing to the 'Abstract' column\n",
    "df['Abstract'] = df['Abstract'].apply(preprocess_text)\n",
    "\n",
    "# Save the cleaned data back to a new CSV file\n",
    "df.to_csv('cleaned_pubmed_abstracts_with_mesh.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edea3a5-15f6-4f28-aa7a-429ad0eb9f4a",
   "metadata": {},
   "source": [
    "## Neo4J Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef43014-db01-41d5-ab6f-ff436e7799b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert entities and relationships into Neo4j\n",
    "def insert_into_neo4j(entities, relationships):\n",
    "    with driver.session() as session:\n",
    "        # Insert entities\n",
    "        for entity in entities:\n",
    "            entity_id = escape_special_chars(entity['id'])\n",
    "            entity_type = escape_special_chars(entity['type'])\n",
    "            query = f\"\"\"\n",
    "            MERGE (e:Entity {{id: '{entity_id}', type: '{entity_type}'}})\n",
    "            \"\"\"\n",
    "            session.run(query)\n",
    "        \n",
    "        # Insert relationships\n",
    "        for relationship in relationships:\n",
    "            source = escape_special_chars(relationship['source'])\n",
    "            target = escape_special_chars(relationship['target'])\n",
    "            relation = escape_special_chars(relationship['relation'].upper().replace(\" \", \"_\"))\n",
    "            query = f\"\"\"\n",
    "            MATCH (source:Entity {{id: '{source}'}}),\n",
    "                  (target:Entity {{id: '{target}'}})\n",
    "            MERGE (source)-[:{relation}]->(target)\n",
    "            \"\"\"\n",
    "            session.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c083bf76-aa4f-48e7-a64e-3667934fea8b",
   "metadata": {},
   "source": [
    "## OpenAi Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc048642-dd5a-4092-a6c9-3cce626c2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "openai.api_key = \"\"  #Insert openai key here\n",
    "# Initialize dynamic sets for known entities and relationships\n",
    "known_entities = set()\n",
    "known_relationships = set()\n",
    "# Function to extract entities and relationships from an abstract using OpenAI with temperature variation\n",
    "def extract_entities_relationships_multiple_runs(abstract, num_runs=3):\n",
    "    combined_entities = []\n",
    "    combined_relationships = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        temperature = 0.3 + (0.4 * (i / (num_runs - 1)))\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Extract the entities and relationships from the following abstract:\n",
    "        {abstract}\n",
    "\n",
    "        Provide the output as a JSON in this format:\n",
    "        {{\n",
    "          \"entities\": [\n",
    "            {{\"id\": \"Entity1\", \"type\": \"Type1\"}},\n",
    "            {{\"id\": \"Entity2\", \"type\": \"Type2\"}}\n",
    "          ],\n",
    "          \"relationships\": [\n",
    "            {{\"source\": \"Entity1\", \"target\": \"Entity2\", \"relation\": \"RELATION_TYPE\"}}\n",
    "          ]\n",
    "        }}\n",
    "        Ensure the output uses double quotes for property names and values.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Make API call to OpenAI\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "\n",
    "        # Parse the response\n",
    "        result = response['choices'][0]['message']['content']\n",
    "        try:\n",
    "            parsed_result = json.loads(result)\n",
    "            entities = parsed_result.get('entities', [])\n",
    "            relationships = parsed_result.get('relationships', [])\n",
    "            \n",
    "            combined_entities.extend(entities)\n",
    "            combined_relationships.extend(relationships)\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON for temperature {temperature}: {result}\")\n",
    "            continue\n",
    "\n",
    "    # Deduplicate and normalize entities and relationships\n",
    "    combined_entities = normalize_and_deduplicate_entities(combined_entities)\n",
    "    combined_relationships = normalize_and_deduplicate_relationships(combined_relationships)\n",
    "    \n",
    "    return combined_entities, combined_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b31b45-c9d5-4d52-955c-3ab9c4a2d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to deduplicate and normalize entities\n",
    "def normalize_and_deduplicate_entities(entities):\n",
    "    global known_entities  # Use the dynamic known_entities set\n",
    "    seen = set()\n",
    "    unique_entities = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        normalized_entity = normalize_entity_name(entity['id'])\n",
    "        if normalized_entity not in seen:\n",
    "            seen.add(normalized_entity)\n",
    "            entity['id'] = normalized_entity  # Update the entity ID to the normalized one\n",
    "            unique_entities.append(entity)\n",
    "            # Update the known_entities set dynamically\n",
    "            known_entities.add(normalized_entity)\n",
    "    \n",
    "    return unique_entities\n",
    "\n",
    "# Function to normalize and deduplicate relationships\n",
    "def normalize_and_deduplicate_relationships(relationships):\n",
    "    global known_relationships  # Use the dynamic known_relationships set\n",
    "    seen = set()\n",
    "    unique_relationships = []\n",
    "    \n",
    "    for relationship in relationships:\n",
    "        source = normalize_entity_name(relationship['source'])\n",
    "        target = normalize_entity_name(relationship['target'])\n",
    "        relation = normalize_relationship_type(relationship['relation'])\n",
    "        \n",
    "        rel_tuple = (source, target, relation)\n",
    "        if rel_tuple not in seen:\n",
    "            seen.add(rel_tuple)\n",
    "            unique_relationships.append({\n",
    "                \"source\": source,\n",
    "                \"target\": target,\n",
    "                \"relation\": relation\n",
    "            })\n",
    "            # Update the known_relationships set dynamically\n",
    "            known_relationships.add(relation)\n",
    "    \n",
    "    return unique_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5864274e-022e-4dd2-972e-b77775364477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize entity names using fuzzy matching\n",
    "def normalize_entity_name(entity_name):\n",
    "    global known_entities  # Use the dynamic set of known entities\n",
    "    if len(known_entities) == 0:\n",
    "        # If the known_entities set is empty, return the entity name as is\n",
    "        return entity_name\n",
    "\n",
    "    # Fuzzy matching against known entities\n",
    "    best_match = process.extractOne(entity_name.lower(), known_entities, scorer=process.fuzz.ratio)\n",
    "    if best_match and best_match[1] > 80:  # Threshold for similarity\n",
    "        return best_match[0]\n",
    "    \n",
    "    return entity_name\n",
    "\n",
    "# Function to normalize relationship types using fuzzy matching\n",
    "def normalize_relationship_type(relation):\n",
    "    global known_relationships  # Use the dynamic set of known relationships\n",
    "    if len(known_relationships) == 0:\n",
    "        # If the known_relationships set is empty, return the relation as is\n",
    "        return relation\n",
    "\n",
    "    # Fuzzy matching against known relationships\n",
    "    best_match = process.extractOne(relation.lower(), known_relationships, scorer=process.fuzz.ratio)\n",
    "    if best_match and best_match[1] > 80:  # Threshold for similarity\n",
    "        return best_match[0]\n",
    "    \n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5bb30bf-6199-4f64-963f-14cd1ff8fd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [{'id': 'Cardiovascular toxicity', 'type': 'Medical condition'}, {'id': 'Angiogenesis inhibitors', 'type': 'Medication'}, {'id': 'Patients with cancer', 'type': 'Patient group'}, {'id': 'Taiwan', 'type': 'Location'}, {'id': 'Observational study', 'type': 'Study type'}, {'id': 'Major adverse cardiovascular events (MACEs)', 'type': 'Medical condition'}, {'id': 'Nested case-control study', 'type': 'Study design'}, {'id': 'Taiwan Cancer Registry', 'type': 'Registry'}, {'id': 'Taiwan National Insurance Claim Database', 'type': 'Database'}, {'id': 'Cases', 'type': 'Data subset'}, {'id': 'Controls', 'type': 'Data subset'}, {'id': 'Age', 'type': 'Demographic factor'}, {'id': 'Sex', 'type': 'Demographic factor'}, {'id': 'Cancer type', 'type': 'Medical condition'}, {'id': 'Cancer diagnosis date', 'type': 'Date'}, {'id': 'Logistic regression', 'type': 'Statistical analysis'}, {'id': 'Propensity score adjustment', 'type': 'Statistical analysis'}, {'id': 'Sensitivity analyses', 'type': 'Statistical analysis'}, {'id': 'Incidence', 'type': 'Measurement'}, {'id': 'Person-years', 'type': 'Measurement'}, {'id': 'Heart failure hospitalization', 'type': 'Medical condition'}, {'id': 'Myocardial infarction', 'type': 'Medical condition'}, {'id': 'Cerebrovascular accident', 'type': 'Medical condition'}, {'id': 'Venous thromboembolism', 'type': 'Medical condition'}, {'id': 'New-onset atrial fibrillation', 'type': 'Medical condition'}, {'id': 'Malignancies', 'type': 'Medical condition'}, {'id': 'Prevalent cases', 'type': 'Health condition'}, {'id': 'Riskset sampling', 'type': 'Methodology'}, {'id': 'Conditional logistic regression', 'type': 'Statistical analysis'}, {'id': 'Cohort of 284,292', 'type': 'Group'}, {'id': 'Atrial fibrillation', 'type': 'Medical condition'}]\n",
      "Relationships: [{'source': 'Cardiovascular toxicity', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with'}, {'source': 'Angiogenesis inhibitors', 'target': 'Patients with cancer', 'relation': 'Used by'}, {'source': 'Patients with cancer', 'target': 'Taiwan', 'relation': 'Located in'}, {'source': 'Observational study', 'target': 'Major adverse cardiovascular events (MACEs)', 'relation': 'Explored risk of'}, {'source': 'Nested case-control study', 'target': 'Taiwan Cancer Registry', 'relation': 'Used data from'}, {'source': 'Taiwan Cancer Registry', 'target': 'Taiwan National Insurance Claim Database', 'relation': 'Linked with'}, {'source': 'Cases', 'target': 'Controls', 'relation': 'Matched with'}, {'source': 'Age', 'target': 'Sex', 'relation': 'Matched by'}, {'source': 'Age', 'target': 'Cancer type', 'relation': 'Matched by'}, {'source': 'Cancer type', 'target': 'Cancer diagnosis date', 'relation': 'Matched by'}, {'source': 'Logistic regression', 'target': 'Major adverse cardiovascular events (MACEs)', 'relation': 'Used to evaluate risks of'}, {'source': 'Propensity score adjustment', 'target': 'Major adverse cardiovascular events (MACEs)', 'relation': 'Used for'}, {'source': 'Sensitivity analyses', 'target': 'Major adverse cardiovascular events (MACEs)', 'relation': 'Used to evaluate risks of'}, {'source': 'Incidence', 'target': 'Person-years', 'relation': 'Calculated as'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'Heart failure hospitalization', 'relation': 'Increased risks of'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'Myocardial infarction', 'relation': 'Increased risks of'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'Cerebrovascular accident', 'relation': 'Increased risks of'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'Venous thromboembolism', 'relation': 'Increased risks of'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'New-onset atrial fibrillation', 'relation': 'Associated with'}, {'source': 'Malignancies', 'target': 'Taiwan', 'relation': 'Located in'}, {'source': 'Malignancies', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with'}, {'source': 'Observational study', 'target': 'Cardiovascular toxicity', 'relation': 'Focuses on'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with'}, {'source': 'Cases', 'target': 'Age', 'relation': 'Matched by'}, {'source': 'Cases', 'target': 'Sex', 'relation': 'Matched by'}, {'source': 'Cases', 'target': 'Cancer type', 'relation': 'Matched by'}, {'source': 'Cases', 'target': 'Cancer diagnosis date', 'relation': 'Matched by'}, {'source': 'Logistic regression', 'target': 'Major adverse cardiovascular events (MACEs)', 'relation': 'Used to evaluate'}, {'source': 'Sensitivity analyses', 'target': 'Major adverse cardiovascular events (MACEs)', 'relation': 'Used for'}, {'source': 'Prevalent cases', 'target': 'Exclusion', 'relation': 'Used for'}, {'source': 'Heart failure hospitalization', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with increased risks of'}, {'source': 'Myocardial infarction', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with increased risks of'}, {'source': 'Cerebrovascular accident', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with increased risks of'}, {'source': 'Venous thromboembolism', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with increased risks of'}, {'source': 'New-onset atrial fibrillation', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with'}, {'source': 'Malignancies', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with increased risks of'}, {'source': 'Cardiovascular toxicity', 'target': 'Angiogenesis inhibitors', 'relation': 'Treatment of'}, {'source': 'Angiogenesis inhibitors', 'target': 'Patients with cancer', 'relation': 'Administered to'}, {'source': 'Taiwan', 'target': 'Observational study', 'relation': 'Location of'}, {'source': 'Major adverse cardiovascular events (MACEs)', 'target': 'Angiogenesis inhibitors', 'relation': 'Associated with increased risks of'}, {'source': 'Angiogenesis inhibitors', 'target': 'Heart failure hospitalization', 'relation': 'Associated with increased risks of'}, {'source': 'Angiogenesis inhibitors', 'target': 'Myocardial infarction', 'relation': 'Associated with increased risks of'}, {'source': 'Angiogenesis inhibitors', 'target': 'Cerebrovascular accident', 'relation': 'Associated with increased risks of'}, {'source': 'Angiogenesis inhibitors', 'target': 'Venous thromboembolism', 'relation': 'Associated with increased risks of'}, {'source': 'Angiogenesis inhibitors', 'target': 'Atrial fibrillation', 'relation': 'Associated with'}]\n"
     ]
    }
   ],
   "source": [
    "abstract = \"\"\"research on the cardiovascular toxicity of angiogenesis inhibitors among patients with cancer in taiwan is lacking this observational study explored the risk of major adverse cardiovascular events maces associated with angiogenesis inhibitors in taiwan we conducted a nested casecontrol study using the tcr taiwan cancer registry linked with the taiwan national insurance claim database we matched every case with 4 controls using riskset sampling by index date age sex cancer type and cancer diagnosis date conditional logistic regression was used to evaluate the risks of maces and different cardiovascular events using propensity score adjustment or matching sensitivity analyses were used to evaluate the risks matched by cancer stages or exposure within 1 year among a cohort of 284 292 after the exclusion of prevalent cases the incidences of maces among the overall cohort and those exposed to angiogenesis inhibitors were 225 and 325 events per 1000 personyears respectively we matched 17 817 cases with 70 740 controls with a mean age of 749 years and 568 of patients were men after propensity score adjustment angiogenesis inhibitors were associated with increased risks of maces odds ratio 456 95 ci 1781159 significantly increased risks were noted for heart failure hospitalization myocardial infarction cerebrovascular accident and venous thromboembolism but not for newonset atrial fibrillation similar results were observed after matching by cancer stage or restriction of 1year exposure angiogenesis inhibitors were associated with increased risks of maces among patients with various malignancies in taiwan but were not associated with newonset atrial fibrillation\n",
    "\"\"\"\n",
    "entities, relationships = extract_entities_relationships_multiple_runs(abstract, num_runs=3)\n",
    "\n",
    "# Print the final entities and relationships\n",
    "print(\"Entities:\", entities)\n",
    "print(\"Relationships:\", relationships)\n",
    "\n",
    "# Connect to Neo4j\n",
    "uri = \"neo4j://localhost:7687\"  # Adjust for your Neo4j instance\n",
    "username = \"neo4j\"\n",
    "password = \"gf6xb4kgeZKSS8p\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to escape special characters for Cypher queries\n",
    "def escape_special_chars(value):\n",
    "    return value.replace(\"'\", \"''\")\n",
    "\n",
    "# Insert deduplicated entities and relationships into Neo4j\n",
    "insert_into_neo4j(entities, relationships)\n",
    "\n",
    "# Close Neo4j connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7613d-c4b3-41f5-94ad-524496958908",
   "metadata": {},
   "source": [
    "## Lang Chain Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b974de-20d2-4966-bbb5-d4f7759b7f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./miniforge3/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./miniforge3/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./miniforge3/lib/python3.10/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./miniforge3/lib/python3.10/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./miniforge3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in ./miniforge3/lib/python3.10/site-packages (from langchain) (0.3.12)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./miniforge3/lib/python3.10/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./miniforge3/lib/python3.10/site-packages (from langchain) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./miniforge3/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./miniforge3/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./miniforge3/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./miniforge3/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./miniforge3/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./miniforge3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./miniforge3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./miniforge3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./miniforge3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: anyio in ./miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./miniforge3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (2.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./miniforge3/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d0f2f6-d442-4a2e-87c5-1c48facde2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  langchain langchain-community langchain-groq neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7fd7e6-c675-4052-96f3-d2f46184f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph DB\n",
    "NEO4J_URI=\"neo4j://localhost:7687\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"gf6xb4kgeZKSS8p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b14e2cb-7882-4965-8a51-53b6b998d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NEO4J_URI\"]=NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"]=NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"]=NEO4J_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3972eea-7854-4ea2-b047-7f4c2b5e032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188f3115-036f-411d-8961-d7a8f14f4ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x28f7a7d90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae1b0d02-20ac-4fd0-9fea-700b6eeb69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e88c935-5343-4d83-bbc2-88e0546de840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7802ba98-08a8-456b-86b0-bc9cfc3af18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x29404e620>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x29404fa60>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8b7c3c6-956e-4a1b-959c-7fae585e2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "865530dc-697c-4024-9c44-2b996f2536d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer=LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48237a52-36b8-4081-968d-ab30f2b67355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphCypherQAChain(verbose=True, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x28f7a7d90>, cypher_generation_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x29404e620>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x29404fa60>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), qa_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x29404e620>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x29404fa60>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), graph_schema='Node properties are the following:\\nEntity {type: STRING, id: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Entity)-[:TREATMENT_OF]->(:Entity),(:Entity)-[:ASSOCIATED_WITH]->(:Entity),(:Entity)-[:USED_BY]->(:Entity),(:Entity)-[:ADMINISTERED_TO]->(:Entity),(:Entity)-[:ASSOCIATED_WITH_INCREASED_RISKS_OF]->(:Entity),(:Entity)-[:LOCATED_IN]->(:Entity),(:Entity)-[:LOCATION_OF]->(:Entity),(:Entity)-[:FOCUSES_ON]->(:Entity),(:Entity)-[:EXPLORED_RISK_OF]->(:Entity),(:Entity)-[:INCREASED_RISKS_OF]->(:Entity),(:Entity)-[:USED_DATA_FROM]->(:Entity),(:Entity)-[:LINKED_WITH]->(:Entity),(:Entity)-[:MATCHED_BY]->(:Entity),(:Entity)-[:MATCHED_WITH]->(:Entity),(:Entity)-[:USED_TO_EVALUATE]->(:Entity),(:Entity)-[:USED_TO_EVALUATE_RISKS_OF]->(:Entity),(:Entity)-[:USED_FOR]->(:Entity),(:Entity)-[:CALCULATED_AS]->(:Entity)', allow_dangerous_requests=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "chain = GraphCypherQAChain.from_llm(llm=llm, graph = graph, verbose = True, allow_dangerous_requests = True)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7abd4cf0-4e09-4a8b-adc9-a927aba6e4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The semantics of using colon in the separation of alternative relationship types will change in a future version. (Please use ':FOCUSES_ON|EXPLORED_RISK_OF' instead)} {position: line: 1, column: 30, offset: 29} for query: 'MATCH (e:Entity)-[:FOCUSES_ON|:EXPLORED_RISK_OF]->(m:Entity) WHERE m.type = \"Medical condition\" RETURN DISTINCT e.id AS id, e.type AS type, m.id AS medical_condition_id, m.type AS medical_condition_type;'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (e:Entity)-[:FOCUSES_ON|:EXPLORED_RISK_OF]->(m:Entity) WHERE m.type = \"Medical condition\" RETURN DISTINCT e.id AS id, e.type AS type, m.id AS medical_condition_id, m.type AS medical_condition_type;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'id': 'Observational study', 'type': 'Study type', 'medical_condition_id': 'Major adverse cardiovascular events (MACEs)', 'medical_condition_type': 'Medical condition'}, {'id': 'Observational study', 'type': 'Study type', 'medical_condition_id': 'Cardiovascular toxicity', 'medical_condition_type': 'Medical condition'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are different Medical condition',\n",
       " 'result': 'Major adverse cardiovascular events (MACEs), Cardiovascular toxicity.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\": \"What are different Medical condition\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bde0cbf1-24d6-4183-a1e5-b272702474e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: RISK_OF)} {position: line: 1, column: 41, offset: 40} for query: 'MATCH p=(e1:Entity)-[r:USED_TO_EVALUATE|RISK_OF]->(e2:Entity) RETURN p;'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH p=(e1:Entity)-[r:USED_TO_EVALUATE|RISK_OF]->(e2:Entity) RETURN p;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p': [{'id': 'Logistic regression', 'type': 'Statistical analysis'}, 'USED_TO_EVALUATE', {'id': 'Major adverse cardiovascular events (MACEs)', 'type': 'Medical condition'}]}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Statistical analysis relation',\n",
       " 'result': 'Logistic regression is used to evaluate Major adverse cardiovascular events (MACEs).'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\": \"Statistical analysis relation\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2cb30b5f-27f7-4eb4-9792-860bd11a5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH p = shortestPath((:Entity {type: \"Medical condition\", id: \"Malignancies\"})-[*..10]-(e:Entity {type: \"Medication\", id: \"Angiogenesis inhibitors\"})) RETURN p;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p': [{'id': 'Malignancies', 'type': 'Medical condition'}, 'ASSOCIATED_WITH_INCREASED_RISKS_OF', {'id': 'Angiogenesis inhibitors', 'type': 'Medication'}]}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How is Medical condition Malignancies to Medication Angiogenesis inhibitors',\n",
       " 'result': 'Malignancies is associated with increased risks of Angiogenesis inhibitors.'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\": \"How is Medical condition Malignancies to Medication Angiogenesis inhibitors\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84d0c4-ddcb-4f71-b043-3f41cfe12d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
